{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_csv('Processed_Headings/normalized_section_data 2.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna(subset=['sec-norm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_grouped = df.groupby([\"PMCID\", \"PMID\"]).agg(list)\n",
    "# df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def convert_to_sep_format(row):\n",
    "#     titles = row[\"sec-title\"]  # 取得標題列表\n",
    "#     labels = row[\"sec-norm\"]   # 取得標籤列表\n",
    "\n",
    "#     # 插入 `[SEP]`\n",
    "#     inputs_with_sep = []\n",
    "#     labels_with_sep = []\n",
    "\n",
    "#     for i, title in enumerate(titles):\n",
    "#         inputs_with_sep.append(title)\n",
    "#         labels_with_sep.append(\"O\")  # 一般 token 標記為 \"O\"\n",
    "        \n",
    "#         # 在每個標題後面插入 [SEP]，對應標籤來自 sec-norm\n",
    "#         if i < len(labels):  # 確保標籤數量正確\n",
    "#             inputs_with_sep.append(\"[SEP]\")\n",
    "#             labels_with_sep.append(labels[i])  # 讓 [SEP] 位置承擔標籤\n",
    "\n",
    "#     return pd.Series([inputs_with_sep, labels_with_sep])\n",
    "\n",
    "# # 對 DataFrame 進行轉換\n",
    "# df_grouped[[\"inputs_with_sep\", \"labels_with_sep\"]] = df_grouped.apply(convert_to_sep_format, axis=1)\n",
    "\n",
    "# df_grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_grouped = df_grouped.drop(columns=['sec-type', 'sec-title', 'sec-norm'])\n",
    "# df_grouped.to_csv('Processed_Headings/grouped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_grouped = pd.read_csv('Processed_Headings/grouped.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMCID</th>\n",
       "      <th>PMID</th>\n",
       "      <th>inputs_with_sep</th>\n",
       "      <th>labels_with_sep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PMC10000014</td>\n",
       "      <td>36921129</td>\n",
       "      <td>['INTRODUCTION', '[SEP]', 'METHODS', '[SEP]', ...</td>\n",
       "      <td>['O', 'background', 'O', 'methods', 'O', 'resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PMC10000015</td>\n",
       "      <td>36909079</td>\n",
       "      <td>['Introduction', '[SEP]', 'Case presentation',...</td>\n",
       "      <td>['O', 'background', 'O', 'methods', 'O', 'conc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PMC10000017</td>\n",
       "      <td>36921128</td>\n",
       "      <td>['INTRODUCTION', '[SEP]', 'METHODS', '[SEP]', ...</td>\n",
       "      <td>['O', 'background', 'O', 'methods', 'O', 'resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PMC10000020</td>\n",
       "      <td>34107125</td>\n",
       "      <td>['Introduction', '[SEP]', 'Results', '[SEP]', ...</td>\n",
       "      <td>['O', 'background', 'O', 'results', 'O', 'resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PMC10000021</td>\n",
       "      <td>36583948</td>\n",
       "      <td>['INTRODUCTION', '[SEP]', 'MATERIALS AND METHO...</td>\n",
       "      <td>['O', 'background', 'O', 'methods', 'O', 'resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4654684</th>\n",
       "      <td>PMC9999731</td>\n",
       "      <td>36911530</td>\n",
       "      <td>['Introduction', '[SEP]', 'Materials and metho...</td>\n",
       "      <td>['O', 'background', 'O', 'methods', 'O', 'resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4654685</th>\n",
       "      <td>PMC9999732</td>\n",
       "      <td>34391118</td>\n",
       "      <td>['Introduction', '[SEP]', 'Methods', '[SEP]', ...</td>\n",
       "      <td>['O', 'background', 'O', 'methods', 'O', 'resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4654686</th>\n",
       "      <td>PMC9999914</td>\n",
       "      <td>36936403</td>\n",
       "      <td>['Introduction', '[SEP]', 'Methods', '[SEP]', ...</td>\n",
       "      <td>['O', 'background', 'O', 'methods', 'O', 'resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4654687</th>\n",
       "      <td>PMC9999942</td>\n",
       "      <td>36920160</td>\n",
       "      <td>['Introduction', '[SEP]', 'Conclusions', '[SEP]']</td>\n",
       "      <td>['O', 'background', 'O', 'conclusions']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4654688</th>\n",
       "      <td>PMC9999943</td>\n",
       "      <td>36827526</td>\n",
       "      <td>['Introduction', '[SEP]', 'Methods', '[SEP]', ...</td>\n",
       "      <td>['O', 'background', 'O', 'methods', 'O', 'conc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4654689 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               PMCID      PMID  \\\n",
       "0        PMC10000014  36921129   \n",
       "1        PMC10000015  36909079   \n",
       "2        PMC10000017  36921128   \n",
       "3        PMC10000020  34107125   \n",
       "4        PMC10000021  36583948   \n",
       "...              ...       ...   \n",
       "4654684   PMC9999731  36911530   \n",
       "4654685   PMC9999732  34391118   \n",
       "4654686   PMC9999914  36936403   \n",
       "4654687   PMC9999942  36920160   \n",
       "4654688   PMC9999943  36827526   \n",
       "\n",
       "                                           inputs_with_sep  \\\n",
       "0        ['INTRODUCTION', '[SEP]', 'METHODS', '[SEP]', ...   \n",
       "1        ['Introduction', '[SEP]', 'Case presentation',...   \n",
       "2        ['INTRODUCTION', '[SEP]', 'METHODS', '[SEP]', ...   \n",
       "3        ['Introduction', '[SEP]', 'Results', '[SEP]', ...   \n",
       "4        ['INTRODUCTION', '[SEP]', 'MATERIALS AND METHO...   \n",
       "...                                                    ...   \n",
       "4654684  ['Introduction', '[SEP]', 'Materials and metho...   \n",
       "4654685  ['Introduction', '[SEP]', 'Methods', '[SEP]', ...   \n",
       "4654686  ['Introduction', '[SEP]', 'Methods', '[SEP]', ...   \n",
       "4654687  ['Introduction', '[SEP]', 'Conclusions', '[SEP]']   \n",
       "4654688  ['Introduction', '[SEP]', 'Methods', '[SEP]', ...   \n",
       "\n",
       "                                           labels_with_sep  \n",
       "0        ['O', 'background', 'O', 'methods', 'O', 'resu...  \n",
       "1        ['O', 'background', 'O', 'methods', 'O', 'conc...  \n",
       "2        ['O', 'background', 'O', 'methods', 'O', 'resu...  \n",
       "3        ['O', 'background', 'O', 'results', 'O', 'resu...  \n",
       "4        ['O', 'background', 'O', 'methods', 'O', 'resu...  \n",
       "...                                                    ...  \n",
       "4654684  ['O', 'background', 'O', 'methods', 'O', 'resu...  \n",
       "4654685  ['O', 'background', 'O', 'methods', 'O', 'resu...  \n",
       "4654686  ['O', 'background', 'O', 'methods', 'O', 'resu...  \n",
       "4654687            ['O', 'background', 'O', 'conclusions']  \n",
       "4654688  ['O', 'background', 'O', 'methods', 'O', 'conc...  \n",
       "\n",
       "[4654689 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "MAX_LENGTH = 20  # 你希望的最大序列長度\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    自定義 collate_fn，對 batch 進行動態 padding，並確保不超過 max_length\n",
    "    \"\"\"\n",
    "    input_ids = [b[0].tolist()[:MAX_LENGTH] for b in batch]  # 確保不超過 MAX_LENGTH\n",
    "    attention_mask = [b[1].tolist()[:MAX_LENGTH] for b in batch]\n",
    "    labels = [b[2].tolist()[:MAX_LENGTH] for b in batch]\n",
    "\n",
    "    # 找到 batch 中的最大長度\n",
    "    batch_max_len = min(MAX_LENGTH, max(len(seq) for seq in input_ids))\n",
    "\n",
    "    # Padding\n",
    "    tokenizer_pad_id = tokenizer.pad_token_id if tokenizer.pad_token_id else 0\n",
    "    input_ids_padded = torch.tensor([seq + [tokenizer_pad_id] * (batch_max_len - len(seq)) for seq in input_ids])\n",
    "    attention_mask_padded = torch.tensor([seq + [0] * (batch_max_len - len(seq)) for seq in attention_mask])\n",
    "    labels_padded = torch.tensor([seq + [-1] * (batch_max_len - len(seq)) for seq in labels])  # -1 for ignored labels in CRF\n",
    "\n",
    "    return input_ids_padded, attention_mask_padded, labels_padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "# 載入 BERT Tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# 建立標籤映射表\n",
    "\n",
    "label2id = {\"O\": 0, \"objective\": 1, \"background\": 2, \"methods\": 3, \"results\": 4, \"conclusions\": 5}\n",
    "# label2id = defaultdict(int, label2id)\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "class SectionDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=MAX_LENGTH):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # Tokenize input\n",
    "        encoded = self.tokenizer(['[CLS]'] + eval(row[\"inputs_with_sep\"]), \n",
    "                                 is_split_into_words=True, \n",
    "                                 padding=\"max_length\", \n",
    "                                 truncation=True, \n",
    "                                 max_length=self.max_length, \n",
    "                                 return_tensors=\"pt\")\n",
    "\n",
    "        input_ids = encoded[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = encoded[\"attention_mask\"].squeeze(0)\n",
    "\n",
    "        # 轉換標籤為數字 index，並填充 padding\n",
    "        labels = [0]+ [label2id[label] for label in eval(row[\"labels_with_sep\"]) if label in label2id]\n",
    "        labels = labels + [-1] * (self.max_length - len(labels))  # 用 -1 填充\n",
    "        labels = torch.tensor(labels)\n",
    "        \n",
    "        # print(len(input_ids), len(attention_mask), len(labels))\n",
    "        return input_ids, attention_mask, labels\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df_grouped[:len(df_grouped)//40], test_size=0.1, random_state=49, shuffle=True)\n",
    "\n",
    "train_dataset = SectionDataset(train_df, tokenizer)\n",
    "test_dataset = SectionDataset(test_df, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=True, collate_fn=collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([  101,   101,  4955,   102,  4118,   102,  3463,   102,  6594,   102,\n",
      "        27024,  3430,   102,   102,     0,     0,     0,     0,     0,     0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]), tensor([ 0,  0,  2,  0,  3,  0,  4,  0,  5,  0,  2, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1]))\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset[0]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip uninstall TorchCRF\n",
    "# !pip install transformers==4.30.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "from torchcrf import CRF\n",
    "\n",
    "class BERT_CRF(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(BERT_CRF, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.hidden_dim = self.bert.config.hidden_size\n",
    "        self.fc = nn.Linear(self.hidden_dim, num_labels)  # 轉換為標籤 logits\n",
    "        self.crf = CRF(num_labels, batch_first=True)  # CRF 層\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state  # (batch_size, seq_len, hidden_dim)\n",
    "        emissions = self.fc(sequence_output)  # (batch_size, seq_len, num_labels)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = -self.crf(emissions, labels, mask=attention_mask.byte(), reduction=\"mean\")\n",
    "            return loss\n",
    "        else:\n",
    "            predictions = self.crf.decode(emissions, mask=attention_mask.byte())\n",
    "            return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1048/1048 [03:12<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Loss: 824.9436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1048/1048 [03:12<00:00,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2, Loss: 202.8295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 初始化模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERT_CRF(num_labels=len(label2id)).to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(input_ids, attention_mask, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Labels: 35241, Pred Labels: 35241\n",
      "Unique True Labels: {'methods', 'conclusions', 'objective', 'results', 'background', 'O'}\n",
      "Unique Pred Labels: {'methods', 'conclusions', 'results', 'background', 'O'}\n",
      "Test Precision: 0.7844\n",
      "Test Recall: 0.7812\n",
      "Test F1 Score: 0.7820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "model.eval()\n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "        predictions = model(input_ids, attention_mask)\n",
    "\n",
    "        for pred, true, tokens in zip(predictions, labels, input_ids):\n",
    "            pred_labels = []\n",
    "            true_labels = []\n",
    "\n",
    "            for idx, (pred_idx, true_idx, token) in enumerate(zip(pred, true, tokens)):\n",
    "                word = tokenizer.decode([token.item()])\n",
    "                if word == \"[SEP]\" and true_idx.item() != -1:\n",
    "                    pred_labels.append(id2label[pred_idx])\n",
    "                    true_labels.append(id2label[true_idx.item()])\n",
    "\n",
    "\n",
    "            if len(pred_labels) == len(true_labels):  # 確保長度匹配\n",
    "                all_pred_labels.extend(pred_labels)\n",
    "                all_true_labels.extend(true_labels)\n",
    "\n",
    "print(f\"True Labels: {len(all_true_labels)}, Pred Labels: {len(all_pred_labels)}\")\n",
    "print(f\"Unique True Labels: {set(all_true_labels)}\")\n",
    "print(f\"Unique Pred Labels: {set(all_pred_labels)}\")\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    all_true_labels, all_pred_labels, average=\"macro\"\n",
    ")\n",
    "\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision: 0.9928\n",
      "Test Recall: 0.9923\n",
      "Test F1 Score: 0.9923\n",
      "Test Accuracy: 0.9922817173178967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    all_true_labels, all_pred_labels, average=\"weighted\"\n",
    ")\n",
    "\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_score(all_true_labels, all_pred_labels)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
