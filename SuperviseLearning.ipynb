{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19dc6f4a-a5e4-4288-99d3-5308c3e39c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "methods: 1492\n",
      "background: 215\n",
      "results: 314\n",
      "conclusions: 488\n",
      "objective: 523\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "with open('structured_abstract_sections.pkl', 'rb') as f:\n",
    "    normalized_sections = pickle.load(f)\n",
    "\n",
    "sentences = []\n",
    "indices = []\n",
    "for normal_sect in normalized_sections:\n",
    "    print(f'{normal_sect}: {len(normalized_sections[normal_sect])}')\n",
    "    index = [len(sentences)]\n",
    "    sentences += normalized_sections[normal_sect]\n",
    "    index.append(len(sentences))\n",
    "    indices.append(index)\n",
    "    \n",
    "labels = np.zeros(indices[-1][1], dtype=int)  # 創建一個與最大索引一致的 0 陣列\n",
    "\n",
    "# 根據 indices 填充標籤\n",
    "for i, (start, end) in enumerate(indices):\n",
    "    labels[start:end] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd2ce8e-8ac3-4ca7-94d7-ff56992eef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "import pandas\n",
    "\n",
    "fine_tuned_model = SentenceTransformer(\"models/fine_tuned_sentence_bert_model_ContrastiveLoss\")\n",
    "\n",
    "# 測試新模型\n",
    "embeddings = fine_tuned_model.encode(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13a77ba6-acf7-4977-b459-931bd1e5f3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3032, 384)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfe12253-9a09-4474-9491-6752052f4cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1. 定義 PyTorch Dataset，先 shuffle 再存入\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        embeddings = np.array(embeddings, dtype=np.float32)\n",
    "        labels = np.array(labels, dtype=np.longlong)\n",
    "\n",
    "        # 先隨機打亂索引\n",
    "        indices = np.arange(len(labels))\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        # 根據打亂的索引重新排列 embeddings 和 labels\n",
    "        self.embeddings = torch.tensor(embeddings[indices], dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels[indices], dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfba7069-2359-4bad-bdbe-91479db1e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 定義分類模型\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(embedding_dim, 128)  # 隱藏層 128 維\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)  # 輸出層\n",
    "        self.softmax = nn.LogSoftmax(dim=1)  # 可改用 CrossEntropyLoss 不需明確 softmax\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x  # CrossEntropyLoss 會處理 softmax，所以這裡不需 softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cef78963-b34a-421f-b700-46175d96350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 創建 Dataset & DataLoader\n",
    "from tqdm import tqdm\n",
    "def train_model(train_loader, model, epochs=10, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(f'epoch {epoch}:')\n",
    "        total_loss = 0\n",
    "        for batch_embeddings, batch_labels in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_embeddings)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1734568c-02f9-4a62-a0ac-415f7c592683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_loader, model):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch_embeddings, batch_labels in test_loader:\n",
    "            outputs = model(batch_embeddings)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            correct += (predictions == batch_labels).sum().item()\n",
    "            total += batch_labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "780b1ba7-c660-44b0-b4fe-3b2dbca65e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 812.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 64.5294\n",
      "epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 853.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 5.2218\n",
      "epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 864.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 1.1370\n",
      "epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 833.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.5337\n",
      "epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 836.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.3191\n",
      "epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 886.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.2147\n",
      "epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 839.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.1543\n",
      "epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 838.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.1167\n",
      "epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 801.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.0918\n",
      "epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 797.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.0742\n",
      "Test Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "num_samples = embeddings.shape[0]\n",
    "embedding_dim = embeddings.shape[1]\n",
    "num_classes = 5\n",
    "\n",
    "train_embeddings, test_embeddings, train_labels, test_labels = train_test_split(\n",
    "    embeddings, labels, test_size=0.1, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# 7. 創建 PyTorch Dataset & DataLoader\n",
    "train_dataset = EmbeddingDataset(train_embeddings, train_labels)\n",
    "test_dataset = EmbeddingDataset(test_embeddings, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# 8. 初始化並訓練模型\n",
    "model = Classifier(embedding_dim, num_classes)\n",
    "trained_model = train_model(train_loader, model)\n",
    "\n",
    "# 9. 測試模型\n",
    "evaluate_model(test_loader, trained_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "428ac7f0-09da-48eb-b3cf-c23c77d52b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:00<00:00, 863.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 62.9716\n",
      "epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:00<00:00, 894.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 3.4928\n",
      "epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:00<00:00, 870.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.8722\n",
      "epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:00<00:00, 848.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.4247\n",
      "epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:00<00:00, 843.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.2569\n",
      "epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:00<00:00, 876.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.1736\n",
      "epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:00<00:00, 876.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.1258\n",
      "epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:00<00:00, 846.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.0955\n",
      "epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:00<00:00, 813.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.0750\n",
      "epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:00<00:00, 839.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.0606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = EmbeddingDataset(embeddings, labels)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model = Classifier(embedding_dim, num_classes)\n",
    "trained_model = train_model(loader, model)\n",
    "\n",
    "torch.save(model, \"classifier_model.pth\")  # 或者用 .pt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
