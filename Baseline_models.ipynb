{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: tqdm in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /jet/home/slin23/.local/lib/python3.12/site-packages (from sentence-transformers) (2.6.0+cu126)\n",
      "Requirement already satisfied: scikit-learn in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: setuptools in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /jet/home/slin23/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /jet/home/slin23/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /jet/home/slin23/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /jet/home/slin23/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /jet/home/slin23/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /jet/home/slin23/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /jet/home/slin23/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /jet/home/slin23/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /jet/home/slin23/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /jet/home/slin23/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /jet/home/slin23/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /jet/home/slin23/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /jet/home/slin23/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /jet/home/slin23/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: triton==3.2.0 in /jet/home/slin23/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "Downloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m172.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m148.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed huggingface-hub-0.28.1 safetensors-0.5.2 sentence-transformers-3.4.1 tokenizers-0.21.0 transformers-4.48.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('PMCXML6.tsv', delimiter='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "to_add_list = []\n",
    "for text in df['title']:\n",
    "    parts = text.split('>')\n",
    "\n",
    "    \n",
    "    to_add_list.append(parts[2].strip())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15234,\n",
       " 15235,\n",
       " 78921,\n",
       " 78922,\n",
       " 78923,\n",
       " 78924,\n",
       " 82862,\n",
       " 82863,\n",
       " 82864,\n",
       " 82865,\n",
       " 82866,\n",
       " 82867,\n",
       " 82868,\n",
       " 82869,\n",
       " 82870,\n",
       " 82871,\n",
       " 82873,\n",
       " 82875,\n",
       " 82877,\n",
       " 82879,\n",
       " 82881,\n",
       " 82884,\n",
       " 107686,\n",
       " 107687,\n",
       " 107688,\n",
       " 107689,\n",
       " 107690,\n",
       " 107691,\n",
       " 107692,\n",
       " 107693,\n",
       " 107694,\n",
       " 107695,\n",
       " 107696,\n",
       " 107697,\n",
       " 107698,\n",
       " 107699,\n",
       " 107700,\n",
       " 107701,\n",
       " 107702,\n",
       " 107703,\n",
       " 107704,\n",
       " 107705,\n",
       " 107706,\n",
       " 107707,\n",
       " 107708,\n",
       " 107709,\n",
       " 107710,\n",
       " 107711,\n",
       " 107712,\n",
       " 107713,\n",
       " 107714,\n",
       " 107715,\n",
       " 107716,\n",
       " 107717,\n",
       " 107718,\n",
       " 107719,\n",
       " 107720,\n",
       " 107721,\n",
       " 107722,\n",
       " 107723,\n",
       " 107724,\n",
       " 107725,\n",
       " 107726,\n",
       " 107727,\n",
       " 107728,\n",
       " 107729,\n",
       " 107730,\n",
       " 107731,\n",
       " 107732,\n",
       " 107733,\n",
       " 107734,\n",
       " 107735,\n",
       " 107736,\n",
       " 107737,\n",
       " 107738,\n",
       " 107739,\n",
       " 107740,\n",
       " 107741,\n",
       " 107742,\n",
       " 107743,\n",
       " 107744,\n",
       " 107745,\n",
       " 107746,\n",
       " 107747,\n",
       " 107748,\n",
       " 107749,\n",
       " 122389,\n",
       " 122390,\n",
       " 262717,\n",
       " 262718,\n",
       " 285989,\n",
       " 285990,\n",
       " 285991,\n",
       " 285992,\n",
       " 285993,\n",
       " 285994,\n",
       " 285995,\n",
       " 285996,\n",
       " 301359,\n",
       " 301361,\n",
       " 301363,\n",
       " 301365,\n",
       " 301367,\n",
       " 301369,\n",
       " 301371,\n",
       " 301373,\n",
       " 301375,\n",
       " 301377,\n",
       " 301380,\n",
       " 301383,\n",
       " 301386,\n",
       " 301389,\n",
       " 301391,\n",
       " 301393,\n",
       " 301395,\n",
       " 301398,\n",
       " 301401,\n",
       " 301405,\n",
       " 301408,\n",
       " 301410,\n",
       " 301412,\n",
       " 301414,\n",
       " 301416,\n",
       " 301418,\n",
       " 301420,\n",
       " 301422,\n",
       " 301424,\n",
       " 301426,\n",
       " 301428,\n",
       " 301430,\n",
       " 301432,\n",
       " 301434,\n",
       " 301436,\n",
       " 301438,\n",
       " 301440,\n",
       " 301442,\n",
       " 301444,\n",
       " 301446,\n",
       " 301448,\n",
       " 301450,\n",
       " 301452,\n",
       " 301454,\n",
       " 301456,\n",
       " 301459,\n",
       " 301464,\n",
       " 301468,\n",
       " 301472,\n",
       " 301476,\n",
       " 301479,\n",
       " 301483,\n",
       " 301485,\n",
       " 301489,\n",
       " 301491,\n",
       " 301494,\n",
       " 301498,\n",
       " 301500,\n",
       " 301502,\n",
       " 301504,\n",
       " 301506,\n",
       " 301508,\n",
       " 301510,\n",
       " 301512,\n",
       " 527189,\n",
       " 527190,\n",
       " 537915,\n",
       " 537918,\n",
       " 545301,\n",
       " 545302,\n",
       " 545303,\n",
       " 545304,\n",
       " 545305,\n",
       " 545306,\n",
       " 545307,\n",
       " 545308,\n",
       " 545309,\n",
       " 545310,\n",
       " 545311,\n",
       " 545312,\n",
       " 545313,\n",
       " 545314,\n",
       " 545316,\n",
       " 545318,\n",
       " 648619,\n",
       " 648620,\n",
       " 648621,\n",
       " 648622,\n",
       " 904108,\n",
       " 904109,\n",
       " 948912,\n",
       " 948914,\n",
       " 948916,\n",
       " 948918,\n",
       " 964139,\n",
       " 964141,\n",
       " 1020049,\n",
       " 1020050,\n",
       " 1020051,\n",
       " 1020052,\n",
       " 1088663,\n",
       " 1088664,\n",
       " 1230594,\n",
       " 1230595,\n",
       " 1392124,\n",
       " 1392126,\n",
       " 1392133,\n",
       " 1392134,\n",
       " 1392135,\n",
       " 1392136,\n",
       " 1392137,\n",
       " 1392138,\n",
       " 1392139,\n",
       " 1392140,\n",
       " 1574111,\n",
       " 1574112,\n",
       " 1574113,\n",
       " 1574114,\n",
       " 1583034,\n",
       " 1583035,\n",
       " 1804999,\n",
       " 1805000,\n",
       " 1973449,\n",
       " 1973450,\n",
       " 1990888,\n",
       " 1990890,\n",
       " 2236300,\n",
       " 2236302,\n",
       " 2266012,\n",
       " 2266013,\n",
       " 2266014,\n",
       " 2266015,\n",
       " 2266016,\n",
       " 2266017,\n",
       " 2266018,\n",
       " 2266019,\n",
       " 2266020,\n",
       " 2266021,\n",
       " 2266022,\n",
       " 2266024,\n",
       " 2266026,\n",
       " 2266028,\n",
       " 2266030,\n",
       " 2266031,\n",
       " 2266032,\n",
       " 2266033,\n",
       " 2266034,\n",
       " 2266035,\n",
       " 2266036,\n",
       " 2266038,\n",
       " 2266040,\n",
       " 2266042,\n",
       " 2266044,\n",
       " 2266046,\n",
       " 2266048,\n",
       " 2266049,\n",
       " 2266050,\n",
       " 2266051,\n",
       " 2266052,\n",
       " 2266053,\n",
       " 2266054,\n",
       " 2266055,\n",
       " 2266056,\n",
       " 2266057,\n",
       " 2266058,\n",
       " 2266059,\n",
       " 2266060,\n",
       " 2266061,\n",
       " 2266062,\n",
       " 2266063,\n",
       " 2266064,\n",
       " 2266065,\n",
       " 2266066,\n",
       " 2266067,\n",
       " 2266068,\n",
       " 2266069,\n",
       " 2266070,\n",
       " 2266071,\n",
       " 2266072,\n",
       " 2266073,\n",
       " 2266074,\n",
       " 2266075,\n",
       " 2266076,\n",
       " 2266077,\n",
       " 2266078,\n",
       " 2266079,\n",
       " 2266080,\n",
       " 2266081,\n",
       " 2266082,\n",
       " 2266083,\n",
       " 2266084,\n",
       " 2266085,\n",
       " 2266086,\n",
       " 2266087,\n",
       " 2266088,\n",
       " 2266089,\n",
       " 2266090,\n",
       " 2266091,\n",
       " 2266092,\n",
       " 2266093,\n",
       " 2266094,\n",
       " 2266095,\n",
       " 2266096,\n",
       " 2266097,\n",
       " 2266098,\n",
       " 2266099,\n",
       " 2266100,\n",
       " 2266101,\n",
       " 2266102,\n",
       " 2266103,\n",
       " 2266104,\n",
       " 2266105,\n",
       " 2266106,\n",
       " 2266107,\n",
       " 2266108,\n",
       " 2266109,\n",
       " 2266110,\n",
       " 2266112,\n",
       " 2266114,\n",
       " 2266115,\n",
       " 2266116,\n",
       " 2266117,\n",
       " 2266118,\n",
       " 2266119,\n",
       " 2266120,\n",
       " 2266121,\n",
       " 2266122,\n",
       " 2266123,\n",
       " 2266124,\n",
       " 2266125,\n",
       " 2266126,\n",
       " 2266128,\n",
       " 2266130,\n",
       " 2266132,\n",
       " 2266133,\n",
       " 2266134,\n",
       " 2295014,\n",
       " 2295016,\n",
       " 2295018,\n",
       " 2295020,\n",
       " 2500817,\n",
       " 2500818,\n",
       " 2514567,\n",
       " 2514568,\n",
       " 2648130,\n",
       " 2648131,\n",
       " 3289949,\n",
       " 3289950,\n",
       " 3905434,\n",
       " 3905435,\n",
       " 3905436,\n",
       " 3905437,\n",
       " 3921703,\n",
       " 3921704,\n",
       " 3921705,\n",
       " 3921706,\n",
       " 3921707,\n",
       " 3921708,\n",
       " 3921709,\n",
       " 3921710]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(len(to_add_list)) if to_add_list[i] == \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fileid                                                   1004673\n",
       "filename       oa_noncomm_xml.PMC010xxxxxx.baseline.2024-06-1...\n",
       "AccessionID                                          PMC10069851\n",
       "pmid                                                    36200858\n",
       "MID                                                  PMC10069851\n",
       "title                          article > back >   > p > ext-link\n",
       "registries                                           NCT04092946\n",
       "tag                                                     ext-link\n",
       "isNCT                                                          1\n",
       "haveAlready                                                    0\n",
       "isReal                                                         1\n",
       "NCTclean                                             NCT04092946\n",
       "section                                                    Other\n",
       "altsection                                                 Other\n",
       "noLic                                                          0\n",
       "NLMPT                                                        NaN\n",
       "MTPT                          prospective studies|clinical study\n",
       "TPscore                                                      NaN\n",
       "Country                                                      USA\n",
       "year                                                      2023.0\n",
       "Name: 78922, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[78922]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'article > body > INTRODUCTION > p'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fileid', 'filename', 'AccessionID', 'pmid', 'MID', 'title',\n",
       "       'registries', 'tag', 'isNCT', 'haveAlready', 'isReal', 'NCTclean',\n",
       "       'section', 'altsection', 'noLic', 'NLMPT', 'MTPT', 'TPscore', 'Country',\n",
       "       'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileid</th>\n",
       "      <th>filename</th>\n",
       "      <th>AccessionID</th>\n",
       "      <th>pmid</th>\n",
       "      <th>MID</th>\n",
       "      <th>title</th>\n",
       "      <th>registries</th>\n",
       "      <th>tag</th>\n",
       "      <th>isNCT</th>\n",
       "      <th>haveAlready</th>\n",
       "      <th>...</th>\n",
       "      <th>NCTclean</th>\n",
       "      <th>section</th>\n",
       "      <th>altsection</th>\n",
       "      <th>noLic</th>\n",
       "      <th>NLMPT</th>\n",
       "      <th>MTPT</th>\n",
       "      <th>TPscore</th>\n",
       "      <th>Country</th>\n",
       "      <th>year</th>\n",
       "      <th>section_original_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>925751</td>\n",
       "      <td>oa_comm_xml.incr.2024-06-28.tar.gz:PMC010xxxxx...</td>\n",
       "      <td>PMC10515754</td>\n",
       "      <td>37745325</td>\n",
       "      <td>PMC10515754</td>\n",
       "      <td>article &gt; back &gt; ack &gt; p &gt; ext-link</td>\n",
       "      <td>NCT00001360</td>\n",
       "      <td>ext-link</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NCT00001360</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>preprint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>ack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>925752</td>\n",
       "      <td>oa_comm_xml.incr.2024-06-28.tar.gz:PMC010xxxxx...</td>\n",
       "      <td>PMC10749708</td>\n",
       "      <td>37622521</td>\n",
       "      <td>PMC10749708</td>\n",
       "      <td>article &gt; body &gt; INTRODUCTION &gt; p</td>\n",
       "      <td>NCT02770716</td>\n",
       "      <td>p</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NCT02770716</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retrospective studies|multicenter study</td>\n",
       "      <td>0.999005</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>925753</td>\n",
       "      <td>oa_comm_xml.incr.2024-06-28.tar.gz:PMC010xxxxx...</td>\n",
       "      <td>PMC10749708</td>\n",
       "      <td>37622521</td>\n",
       "      <td>PMC10749708</td>\n",
       "      <td>article &gt; body &gt; INTRODUCTION &gt; p</td>\n",
       "      <td>NCT01143246</td>\n",
       "      <td>p</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NCT01143246</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retrospective studies|multicenter study</td>\n",
       "      <td>0.983015</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>925754</td>\n",
       "      <td>oa_comm_xml.incr.2024-06-28.tar.gz:PMC010xxxxx...</td>\n",
       "      <td>PMC10749708</td>\n",
       "      <td>37622521</td>\n",
       "      <td>PMC10749708</td>\n",
       "      <td>article &gt; body &gt; INTRODUCTION &gt; p</td>\n",
       "      <td>NCT02770716</td>\n",
       "      <td>p</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NCT02770716</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retrospective studies|multicenter study</td>\n",
       "      <td>0.999005</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>925755</td>\n",
       "      <td>oa_comm_xml.incr.2024-06-28.tar.gz:PMC010xxxxx...</td>\n",
       "      <td>PMC10749708</td>\n",
       "      <td>37622521</td>\n",
       "      <td>PMC10749708</td>\n",
       "      <td>article &gt; body &gt; INTRODUCTION &gt; p</td>\n",
       "      <td>NCT01143246</td>\n",
       "      <td>p</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NCT01143246</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retrospective studies|multicenter study</td>\n",
       "      <td>0.983015</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fileid                                           filename  AccessionID  \\\n",
       "0  925751  oa_comm_xml.incr.2024-06-28.tar.gz:PMC010xxxxx...  PMC10515754   \n",
       "1  925752  oa_comm_xml.incr.2024-06-28.tar.gz:PMC010xxxxx...  PMC10749708   \n",
       "2  925753  oa_comm_xml.incr.2024-06-28.tar.gz:PMC010xxxxx...  PMC10749708   \n",
       "3  925754  oa_comm_xml.incr.2024-06-28.tar.gz:PMC010xxxxx...  PMC10749708   \n",
       "4  925755  oa_comm_xml.incr.2024-06-28.tar.gz:PMC010xxxxx...  PMC10749708   \n",
       "\n",
       "       pmid          MID                                title   registries  \\\n",
       "0  37745325  PMC10515754  article > back > ack > p > ext-link  NCT00001360   \n",
       "1  37622521  PMC10749708    article > body > INTRODUCTION > p  NCT02770716   \n",
       "2  37622521  PMC10749708    article > body > INTRODUCTION > p  NCT01143246   \n",
       "3  37622521  PMC10749708    article > body > INTRODUCTION > p  NCT02770716   \n",
       "4  37622521  PMC10749708    article > body > INTRODUCTION > p  NCT01143246   \n",
       "\n",
       "        tag  isNCT  haveAlready  ...     NCTclean       section    altsection  \\\n",
       "0  ext-link      1            0  ...  NCT00001360         Other         Other   \n",
       "1         p      1            0  ...  NCT02770716  Introduction  Introduction   \n",
       "2         p      1            0  ...  NCT01143246  Introduction  Introduction   \n",
       "3         p      1            0  ...  NCT02770716  Introduction  Introduction   \n",
       "4         p      1            0  ...  NCT01143246  Introduction  Introduction   \n",
       "\n",
       "  noLic     NLMPT                                     MTPT   TPscore  Country  \\\n",
       "0     0  preprint                                      NaN       NaN      USA   \n",
       "1     0       NaN  retrospective studies|multicenter study  0.999005      USA   \n",
       "2     0       NaN  retrospective studies|multicenter study  0.983015      USA   \n",
       "3     0       NaN  retrospective studies|multicenter study  0.999005      USA   \n",
       "4     0       NaN  retrospective studies|multicenter study  0.983015      USA   \n",
       "\n",
       "     year  section_original_name  \n",
       "0  2024.0                    ack  \n",
       "1  2023.0           INTRODUCTION  \n",
       "2  2023.0           INTRODUCTION  \n",
       "3  2023.0           INTRODUCTION  \n",
       "4  2023.0           INTRODUCTION  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['section_original_name'] = to_add_list\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Other', 'Introduction', 'Article-Metadata', 'Methods', 'Table',\n",
       "       'Results', 'Conclusions'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['section'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "section\n",
       "Other               1679842\n",
       "Table               1174531\n",
       "Methods              689156\n",
       "Article-Metadata     227597\n",
       "Results              200520\n",
       "Introduction         187222\n",
       "Conclusions           19408\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['section'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 'song_document' as features and 'popularity_bin' as the target\n",
    "X = df['section_original_name']\n",
    "y = df['section']\n",
    "\n",
    "y_ordered = pd.Categorical(df['section'], categories=df['section'].unique().tolist(), ordered=False)\n",
    "y_encoded = y_ordered.codes\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Text Encoding: Bag of Words\n",
    "bow_vectorizer = CountVectorizer()\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)\n",
    "\n",
    "# Text Encoding: TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 235028\n",
      "max_resources_: 3760448\n",
      "aggressive_elimination: False\n",
      "factor: 2\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 24\n",
      "n_resources: 235028\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END alpha=0.01, max_iter=1000, tol=0.001;, score=(train=0.697, test=0.700) total time= 1.3min\n",
      "[CV 5/5] END alpha=0.01, max_iter=1000, tol=0.001;, score=(train=0.695, test=0.692) total time= 1.4min[CV 5/5] END alpha=0.01, max_iter=10000, tol=0.001;, score=(train=0.695, test=0.692) total time= 1.4min\n",
      "\n",
      "[CV 2/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.730, test=0.729) total time= 1.3min\n",
      "[CV 3/5] END alpha=0.001, max_iter=1000, tol=0.001;, score=(train=0.727, test=0.731) total time= 1.5min\n",
      "[CV 4/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.729, test=0.729) total time= 1.5min\n",
      "[CV 2/5] END alpha=0.01, max_iter=2000, tol=0.001;, score=(train=0.695, test=0.695) total time= 1.5min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.777, test=0.768) total time= 1.8min\n",
      "[CV 3/5] END alpha=0.01, max_iter=5000, tol=0.001;, score=(train=0.693, test=0.696) total time= 1.5min\n",
      "[CV 2/5] END alpha=0.01, max_iter=10000, tol=0.001;, score=(train=0.695, test=0.695) total time= 1.6min\n",
      "[CV 2/5] END alpha=0.001, max_iter=2000, tol=0.0001;, score=(train=0.730, test=0.729) total time= 1.9min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.770, test=0.767) total time= 1.9min\n",
      "[CV 4/5] END alpha=0.001, max_iter=2000, tol=0.0001;, score=(train=0.729, test=0.729) total time= 1.8min\n",
      "[CV 3/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.727, test=0.731) total time= 1.7min\n",
      "[CV 3/5] END alpha=0.001, max_iter=2000, tol=0.0001;, score=(train=0.727, test=0.731) total time= 1.7min\n",
      "[CV 3/5] END alpha=0.01, max_iter=1000, tol=0.001;, score=(train=0.693, test=0.696) total time= 1.8min\n",
      "[CV 1/5] END alpha=0.01, max_iter=10000, tol=0.001;, score=(train=0.697, test=0.700) total time= 1.6min\n",
      "[CV 3/5] END alpha=0.001, max_iter=5000, tol=0.001;, score=(train=0.727, test=0.731) total time= 1.7min\n",
      "[CV 1/5] END alpha=0.001, max_iter=2000, tol=0.001;, score=(train=0.731, test=0.732) total time= 1.8min\n",
      "[CV 4/5] END alpha=0.001, max_iter=2000, tol=0.001;, score=(train=0.729, test=0.729) total time= 1.8min\n",
      "[CV 3/5] END alpha=0.01, max_iter=2000, tol=0.001;, score=(train=0.693, test=0.696) total time= 1.6min\n",
      "[CV 5/5] END alpha=0.001, max_iter=2000, tol=0.001;, score=(train=0.729, test=0.727) total time= 1.7min\n",
      "[CV 4/5] END alpha=0.001, max_iter=1000, tol=0.0001;, score=(train=0.729, test=0.729) total time= 1.7min\n",
      "[CV 5/5] END alpha=0.001, max_iter=1000, tol=0.0001;, score=(train=0.729, test=0.727) total time= 2.0min[CV 3/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.769, test=0.767) total time= 1.8min\n",
      "\n",
      "[CV 4/5] END alpha=0.01, max_iter=2000, tol=0.001;, score=(train=0.695, test=0.695) total time= 2.0min\n",
      "[CV 1/5] END alpha=0.001, max_iter=10000, tol=0.0001;, score=(train=0.731, test=0.732) total time= 2.0min\n",
      "[CV 1/5] END alpha=0.01, max_iter=2000, tol=0.001;, score=(train=0.697, test=0.700) total time= 1.6min\n",
      "[CV 2/5] END alpha=0.001, max_iter=2000, tol=0.001;, score=(train=0.730, test=0.729) total time= 2.1min\n",
      "[CV 1/5] END alpha=0.001, max_iter=1000, tol=0.001;, score=(train=0.731, test=0.732) total time= 1.9min\n",
      "[CV 3/5] END alpha=0.001, max_iter=10000, tol=0.0001;, score=(train=0.727, test=0.731) total time= 2.1min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.769, test=0.766) total time= 2.1min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.774, test=0.767) total time= 2.1min\n",
      "[CV 3/5] END alpha=0.01, max_iter=10000, tol=0.0001;, score=(train=0.693, test=0.696) total time= 2.2min[CV 1/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.731, test=0.732) total time= 1.9min\n",
      "\n",
      "[CV 3/5] END alpha=0.001, max_iter=1000, tol=0.0001;, score=(train=0.727, test=0.731) total time= 2.2min\n",
      "[CV 5/5] END alpha=0.01, max_iter=2000, tol=0.001;, score=(train=0.695, test=0.692) total time= 2.3min\n",
      "[CV 1/5] END alpha=0.001, max_iter=2000, tol=0.0001;, score=(train=0.731, test=0.732) total time= 2.2min\n",
      "[CV 2/5] END alpha=0.001, max_iter=1000, tol=0.001;, score=(train=0.730, test=0.729) total time= 1.8min\n",
      "[CV 4/5] END alpha=0.001, max_iter=1000, tol=0.001;, score=(train=0.729, test=0.729) total time= 2.2min[CV 1/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.773, test=0.771) total time= 2.2min\n",
      "\n",
      "[CV 2/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.773, test=0.766) total time= 2.1min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.770, test=0.767) total time= 2.2min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.768, test=0.765) total time= 2.1min\n",
      "[CV 2/5] END alpha=0.001, max_iter=5000, tol=0.0001;, score=(train=0.729, test=0.728) total time= 1.7min[CV 4/5] END alpha=0.001, max_iter=5000, tol=0.0001;, score=(train=0.729, test=0.729) total time= 1.7min[CV 1/5] END alpha=0.01, max_iter=5000, tol=0.001;, score=(train=0.697, test=0.700) total time= 1.9min\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.773, test=0.771) total time= 1.5min[CV 1/5] END alpha=0.001, max_iter=5000, tol=0.001;, score=(train=0.731, test=0.732) total time= 1.8min\n",
      "\n",
      "[CV 3/5] END alpha=0.001, max_iter=2000, tol=0.001;, score=(train=0.727, test=0.731) total time= 2.3min\n",
      "[CV 4/5] END alpha=0.01, max_iter=5000, tol=0.001;, score=(train=0.695, test=0.695) total time= 1.6min\n",
      "[CV 5/5] END alpha=0.001, max_iter=10000, tol=0.0001;, score=(train=0.729, test=0.727) total time= 2.3min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.774, test=0.772) total time= 1.9min\n",
      "[CV 1/5] END alpha=0.001, max_iter=5000, tol=0.0001;, score=(train=0.731, test=0.732) total time= 2.3min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.773, test=0.766) total time= 1.9min\n",
      "[CV 5/5] END alpha=0.001, max_iter=1000, tol=0.001;, score=(train=0.728, test=0.727) total time= 2.1min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.769, test=0.767) total time= 1.9min\n",
      "[CV 1/5] END alpha=0.01, max_iter=5000, tol=0.0001;, score=(train=0.697, test=0.700) total time= 2.3min\n",
      "[CV 3/5] END alpha=0.01, max_iter=5000, tol=0.0001;, score=(train=0.693, test=0.696) total time= 2.2min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.772, test=0.770) total time= 1.9min\n",
      "[CV 5/5] END alpha=0.01, max_iter=10000, tol=0.0001;, score=(train=0.695, test=0.692) total time= 2.4min\n",
      "[CV 4/5] END alpha=0.001, max_iter=5000, tol=0.001;, score=(train=0.729, test=0.729) total time= 1.7min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.777, test=0.768) total time= 2.2min\n",
      "[CV 2/5] END alpha=0.001, max_iter=1000, tol=0.0001;, score=(train=0.730, test=0.729) total time= 2.1min\n",
      "[CV 1/5] END alpha=0.001, max_iter=1000, tol=0.0001;, score=(train=0.731, test=0.732) total time= 2.4min\n",
      "[CV 2/5] END alpha=0.01, max_iter=1000, tol=0.001;, score=(train=0.695, test=0.695) total time= 2.4min\n",
      "[CV 3/5] END alpha=0.01, max_iter=1000, tol=0.0001;, score=(train=0.693, test=0.696) total time= 2.4min\n",
      "[CV 2/5] END alpha=0.01, max_iter=5000, tol=0.001;, score=(train=0.695, test=0.695) total time= 2.4min\n",
      "[CV 2/5] END alpha=0.001, max_iter=10000, tol=0.0001;, score=(train=0.730, test=0.729) total time= 1.6min\n",
      "[CV 4/5] END alpha=0.01, max_iter=1000, tol=0.001;, score=(train=0.695, test=0.695) total time= 2.5min[CV 4/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.769, test=0.766) total time= 2.5min\n",
      "\n",
      "[CV 4/5] END alpha=0.01, max_iter=1000, tol=0.0001;, score=(train=0.695, test=0.695) total time= 2.5min\n",
      "[CV 2/5] END alpha=0.01, max_iter=1000, tol=0.0001;, score=(train=0.695, test=0.695) total time= 2.5min\n",
      "[CV 4/5] END alpha=0.01, max_iter=10000, tol=0.001;, score=(train=0.695, test=0.695) total time= 2.5min\n",
      "[CV 5/5] END alpha=0.01, max_iter=5000, tol=0.001;, score=(train=0.695, test=0.692) total time= 2.4min\n",
      "[CV 2/5] END alpha=0.001, max_iter=5000, tol=0.001;, score=(train=0.730, test=0.729) total time= 2.5min\n",
      "[CV 5/5] END alpha=0.001, max_iter=5000, tol=0.001;, score=(train=0.728, test=0.727) total time= 2.5min\n",
      "[CV 5/5] END alpha=0.001, max_iter=5000, tol=0.0001;, score=(train=0.729, test=0.727) total time= 2.4min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.776, test=0.768) total time= 2.4min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.777, test=0.768) total time= 2.5min\n",
      "[CV 5/5] END alpha=0.01, max_iter=2000, tol=0.0001;, score=(train=0.695, test=0.692) total time= 2.5min\n",
      "[CV 1/5] END alpha=0.01, max_iter=10000, tol=0.0001;, score=(train=0.697, test=0.700) total time= 2.5min\n",
      "[CV 4/5] END alpha=0.001, max_iter=10000, tol=0.0001;, score=(train=0.728, test=0.728) total time= 2.5min\n",
      "[CV 5/5] END alpha=0.01, max_iter=5000, tol=0.0001;, score=(train=0.695, test=0.692) total time= 2.5min\n",
      "[CV 5/5] END alpha=0.001, max_iter=2000, tol=0.0001;, score=(train=0.730, test=0.728) total time= 2.5min\n",
      "[CV 4/5] END alpha=0.01, max_iter=10000, tol=0.0001;, score=(train=0.695, test=0.695) total time= 2.3min\n",
      "[CV 5/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.729, test=0.727) total time= 2.3min[CV 1/5] END alpha=0.01, max_iter=1000, tol=0.0001;, score=(train=0.697, test=0.700) total time= 2.4min\n",
      "\n",
      "[CV 2/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.773, test=0.766) total time= 2.5min\n",
      "[CV 2/5] END alpha=0.01, max_iter=2000, tol=0.0001;, score=(train=0.695, test=0.695) total time= 2.5min\n",
      "[CV 3/5] END alpha=0.001, max_iter=5000, tol=0.0001;, score=(train=0.727, test=0.731) total time= 2.6min\n",
      "[CV 3/5] END alpha=0.01, max_iter=10000, tol=0.001;, score=(train=0.693, test=0.696) total time= 2.6min\n",
      "[CV 4/5] END alpha=0.01, max_iter=5000, tol=0.0001;, score=(train=0.695, test=0.695) total time= 2.6min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.769, test=0.766) total time= 2.6min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.769, test=0.767) total time= 2.5min[CV 3/5] END alpha=0.01, max_iter=2000, tol=0.0001;, score=(train=0.693, test=0.696) total time= 2.5min\n",
      "\n",
      "[CV 3/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.771, test=0.768) total time= 2.6min[CV 1/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.771, test=0.769) total time= 2.6min[CV 5/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.776, test=0.767) total time= 2.6min\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.771, test=0.769) total time= 2.5min\n",
      "[CV 2/5] END alpha=0.01, max_iter=5000, tol=0.0001;, score=(train=0.695, test=0.695) total time= 2.6min\n",
      "[CV 2/5] END alpha=0.01, max_iter=10000, tol=0.0001;, score=(train=0.695, test=0.695) total time= 2.6min\n",
      "[CV 1/5] END alpha=0.01, max_iter=2000, tol=0.0001;, score=(train=0.697, test=0.700) total time= 2.7min\n",
      "[CV 5/5] END alpha=0.01, max_iter=1000, tol=0.0001;, score=(train=0.695, test=0.692) total time= 2.7min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.769, test=0.765) total time= 2.7min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.776, test=0.767) total time= 2.6min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.772, test=0.766) total time= 2.7min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.771, test=0.769) total time= 2.7min[CV 4/5] END alpha=0.01, max_iter=2000, tol=0.0001;, score=(train=0.695, test=0.695) total time= 2.7min\n",
      "\n",
      "[CV 3/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.769, test=0.766) total time= 2.7min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.771, test=0.769) total time= 2.7min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.772, test=0.766) total time= 2.7min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.770, test=0.767) total time= 2.7min[CV 3/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.769, test=0.766) total time= 2.7min\n",
      "\n",
      "[CV 2/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.772, test=0.765) total time= 2.7min[CV 5/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.776, test=0.767) total time= 2.7min[CV 4/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.769, test=0.765) total time= 2.7min[CV 4/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.769, test=0.766) total time= 2.7min\n",
      "\n",
      "[CV 5/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.776, test=0.767) total time= 2.7min\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.773, test=0.766) total time= 2.7min\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 12\n",
      "n_resources: 470056\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 3/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.729, test=0.728) total time= 1.4min\n",
      "[CV 4/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.729, test=0.729) total time= 1.4min\n",
      "[CV 1/5] END alpha=0.001, max_iter=2000, tol=0.0001;, score=(train=0.729, test=0.728) total time= 1.7min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.768, test=0.762) total time= 1.6min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.767, test=0.762) total time= 1.6min\n",
      "[CV 3/5] END alpha=0.001, max_iter=1000, tol=0.0001;, score=(train=0.729, test=0.728) total time= 1.7min\n",
      "[CV 2/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.730, test=0.735) total time= 1.7min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.767, test=0.766) total time= 1.7min\n",
      "[CV 5/5] END alpha=0.001, max_iter=2000, tol=0.0001;, score=(train=0.731, test=0.732) total time= 1.8min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.769, test=0.766) total time= 1.8min[CV 3/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.767, test=0.762) total time= 1.8min\n",
      "\n",
      "[CV 1/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.767, test=0.765) total time= 1.8min\n",
      "[CV 4/5] END alpha=0.001, max_iter=2000, tol=0.0001;, score=(train=0.728, test=0.729) total time= 1.7min\n",
      "[CV 5/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.731, test=0.731) total time= 1.9min\n",
      "[CV 5/5] END alpha=0.001, max_iter=1000, tol=0.0001;, score=(train=0.731, test=0.732) total time= 1.9min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.767, test=0.766) total time= 1.9min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.770, test=0.768) total time= 2.0min[CV 3/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.767, test=0.762) total time= 1.9min[CV 2/5] END alpha=0.001, max_iter=1000, tol=0.0001;, score=(train=0.729, test=0.734) total time= 2.0min[CV 3/5] END alpha=0.001, max_iter=2000, tol=0.0001;, score=(train=0.729, test=0.728) total time= 1.9min\n",
      "\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.768, test=0.770) total time= 2.0min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.768, test=0.766) total time= 2.0min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.771, test=0.769) total time= 2.0min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.770, test=0.768) total time= 2.1min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.767, test=0.769) total time= 2.1min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.770, test=0.768) total time= 2.2min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.767, test=0.765) total time= 2.3min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.768, test=0.763) total time= 2.3min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.770, test=0.767) total time= 2.4min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.767, test=0.769) total time= 2.5min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.767, test=0.765) total time= 2.4min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.767, test=0.765) total time= 2.5min[CV 2/5] END alpha=0.001, max_iter=2000, tol=0.001;, score=(train=0.730, test=0.735) total time= 2.6min[CV 4/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.770, test=0.767) total time= 2.5min\n",
      "\n",
      "\n",
      "[CV 4/5] END alpha=0.001, max_iter=2000, tol=0.001;, score=(train=0.729, test=0.729) total time= 2.6min\n",
      "[CV 3/5] END alpha=0.001, max_iter=2000, tol=0.001;, score=(train=0.729, test=0.728) total time= 2.6min\n",
      "[CV 1/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.729, test=0.728) total time= 2.7min[CV 5/5] END alpha=0.001, max_iter=2000, tol=0.001;, score=(train=0.731, test=0.732) total time= 2.6min\n",
      "\n",
      "[CV 1/5] END alpha=0.001, max_iter=2000, tol=0.001;, score=(train=0.729, test=0.728) total time= 2.6min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.771, test=0.768) total time= 2.7min[CV 2/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.767, test=0.769) total time= 2.7min[CV 2/5] END alpha=0.001, max_iter=2000, tol=0.0001;, score=(train=0.729, test=0.734) total time= 2.7min[CV 5/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.770, test=0.769) total time= 2.7min[CV 4/5] END alpha=0.001, max_iter=1000, tol=0.0001;, score=(train=0.729, test=0.729) total time= 2.7min\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[CV 3/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.767, test=0.762) total time= 2.8min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.771, test=0.769) total time= 2.8min\n",
      "[CV 1/5] END alpha=0.001, max_iter=1000, tol=0.0001;, score=(train=0.729, test=0.728) total time= 2.8min[CV 2/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.769, test=0.771) total time= 2.8min\n",
      "\n",
      "[CV 5/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.769, test=0.767) total time= 2.9min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.769, test=0.767) total time= 2.9min[CV 5/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.769, test=0.767) total time= 2.9min\n",
      "\n",
      "[CV 5/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.769, test=0.768) total time= 2.9min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.769, test=0.767) total time= 2.9min[CV 1/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.767, test=0.765) total time= 2.9min[CV 3/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.767, test=0.762) total time= 2.9min\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.767, test=0.769) total time= 2.9min[CV 3/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.767, test=0.762) total time= 2.9min\n",
      "\n",
      "[CV 2/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.767, test=0.769) total time= 2.9min[CV 4/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.769, test=0.767) total time= 2.9min\n",
      "\n",
      "[CV 2/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.767, test=0.769) total time= 2.9min\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 6\n",
      "n_resources: 940112\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.766, test=0.766) total time= 1.0min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.767, test=0.766) total time= 1.5min[CV 4/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.768, test=0.767) total time= 1.5min\n",
      "\n",
      "[CV 5/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.767, test=0.765) total time= 1.5min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.767, test=0.766) total time= 1.6min[CV 4/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.767, test=0.766) total time= 1.6min[CV 2/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.766, test=0.766) total time= 1.6min[CV 1/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.767, test=0.766) total time= 1.6min\n",
      "\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.767, test=0.766) total time= 1.7min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.768, test=0.766) total time= 1.6min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.767, test=0.765) total time= 1.7min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.766, test=0.765) total time= 1.7min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.768, test=0.767) total time= 1.7min[CV 2/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.765, test=0.765) total time= 1.8min\n",
      "\n",
      "[CV 3/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.767, test=0.766) total time= 1.7min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.766, test=0.765) total time= 1.8min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.766, test=0.766) total time= 1.8min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.767, test=0.766) total time= 1.7min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.767, test=0.766) total time= 1.9min[CV 5/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.767, test=0.765) total time= 1.8min\n",
      "\n",
      "[CV 3/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.766, test=0.766) total time= 1.9min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.768, test=0.766) total time= 2.0min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.766, test=0.765) total time= 2.0min[CV 1/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.767, test=0.766) total time= 2.0min[CV 4/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.767, test=0.766) total time= 2.0min\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.766, test=0.766) total time= 2.0min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.766, test=0.764) total time= 2.0min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.765, test=0.765) total time= 2.0min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.766, test=0.764) total time= 2.0min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.766, test=0.765) total time= 2.1min\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 1880224\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.764, test=0.764) total time= 1.1min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.765, test=0.764) total time= 1.6min[CV 3/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.765, test=0.764) total time= 1.6min\n",
      "\n",
      "[CV 1/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.764, test=0.764) total time= 1.6min[CV 3/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.765, test=0.764) total time= 1.6min\n",
      "\n",
      "[CV 3/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.765, test=0.764) total time= 1.6min[CV 2/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.764, test=0.763) total time= 1.6min\n",
      "\n",
      "[CV 1/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.765, test=0.764) total time= 1.7min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.765, test=0.764) total time= 1.6min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.764, test=0.763) total time= 1.7min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.766, test=0.764) total time= 1.7min[CV 4/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.766, test=0.763) total time= 1.7min\n",
      "\n",
      "[CV 5/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.765, test=0.764) total time= 1.7min[CV 4/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.765, test=0.763) total time= 1.8min\n",
      "\n",
      "[CV 2/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.764, test=0.764) total time= 1.8min\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 2\n",
      "n_resources: 3760448\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/home/slin23/.conda/envs/pytorch/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.764, test=0.764) total time= 2.0min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.764, test=0.764) total time= 2.1min[CV 2/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.764, test=0.765) total time= 2.1min\n",
      "\n",
      "[CV 5/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.764, test=0.764) total time= 2.1min[CV 3/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.764, test=0.763) total time= 2.1min\n",
      "\n",
      "[CV 5/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.764, test=0.764) total time= 2.2min[CV 3/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.764, test=0.763) total time= 2.1min\n",
      "\n",
      "[CV 1/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.765, test=0.764) total time= 2.2min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.764, test=0.764) total time= 2.2min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.764, test=0.764) total time= 2.2min\n",
      "Best Parameters: {'alpha': 0.0001, 'max_iter': 1000, 'tol': 0.001}\n",
      "Best Validation F1-score: 0.7640588578409907\n",
      "Best model f1 score: 0.7635342760675888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [1e-4, 1e-3, 1e-2],  \n",
    "    'max_iter': [10000, 5000, 2000, 1000],\n",
    "    'tol': [1e-3, 1e-4]  \n",
    "}\n",
    "\n",
    "grid_search = HalvingGridSearchCV(\n",
    "    estimator=SGDClassifier(loss=\"hinge\"),\n",
    "    param_grid=param_grid,\n",
    "    factor=2,  \n",
    "    cv=5,\n",
    "    scoring=\"f1_weighted\",\n",
    "    n_jobs=-1,\n",
    "    verbose=3\n",
    ")\n",
    "grid_search.fit(X_train_bow, y_train)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Validation F1-score:\", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_bow = best_model.predict(X_test_bow)\n",
    "f1_bow = f1_score(y_test, y_pred_bow, average='weighted')\n",
    "\n",
    "print(\"Best model f1 score:\", f1_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7901504925471725\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 235028\n",
      "max_resources_: 3760448\n",
      "aggressive_elimination: False\n",
      "factor: 2\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 24\n",
      "n_resources: 235028\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.740, test=0.739) total time=   0.9s\n",
      "[CV 2/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.742, test=0.738) total time=  27.6s\n",
      "[CV 5/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.743, test=0.739) total time=  30.4s\n",
      "[CV 4/5] END alpha=0.001, max_iter=1000, tol=0.001;, score=(train=0.719, test=0.714) total time=  31.8s\n",
      "[CV 5/5] END alpha=0.001, max_iter=1000, tol=0.0001;, score=(train=0.718, test=0.713) total time=  35.7s\n",
      "[CV 2/5] END alpha=0.001, max_iter=1000, tol=0.001;, score=(train=0.718, test=0.716) total time=  35.9s\n",
      "[CV 2/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.743, test=0.739) total time=  39.7s\n",
      "[CV 2/5] END alpha=0.001, max_iter=10000, tol=0.0001;, score=(train=0.718, test=0.716) total time=  39.8s\n",
      "[CV 1/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.740, test=0.740) total time=  39.8s\n",
      "[CV 2/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.742, test=0.739) total time=  44.9s\n",
      "[CV 3/5] END alpha=0.001, max_iter=1000, tol=0.0001;, score=(train=0.717, test=0.718) total time=  41.5s\n",
      "[CV 3/5] END alpha=0.001, max_iter=1000, tol=0.001;, score=(train=0.717, test=0.718) total time=  53.2s\n",
      "[CV 2/5] END alpha=0.01, max_iter=10000, tol=0.001;, score=(train=0.693, test=0.688) total time=  48.8s\n",
      "[CV 4/5] END alpha=0.001, max_iter=1000, tol=0.0001;, score=(train=0.719, test=0.714) total time=  41.6s\n",
      "[CV 4/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.744, test=0.736) total time=  58.8s\n",
      "[CV 4/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.744, test=0.736) total time=  58.3s\n",
      "[CV 5/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.743, test=0.739) total time=  58.0s\n",
      "[CV 5/5] END alpha=0.001, max_iter=1000, tol=0.001;, score=(train=0.718, test=0.713) total time=  49.1s\n",
      "[CV 2/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.742, test=0.739) total time=  52.8s\n",
      "[CV 1/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.740, test=0.739) total time=  44.4s\n",
      "[CV 1/5] END alpha=0.001, max_iter=1000, tol=0.001;, score=(train=0.716, test=0.716) total time=  41.8s\n",
      "[CV 1/5] END alpha=0.001, max_iter=1000, tol=0.0001;, score=(train=0.716, test=0.716) total time=  45.6s\n",
      "[CV 1/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.739, test=0.739) total time=  48.8s\n",
      "[CV 3/5] END alpha=0.001, max_iter=2000, tol=0.0001;, score=(train=0.717, test=0.718) total time=  50.2s\n",
      "[CV 3/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.741, test=0.741) total time=  43.2s\n",
      "[CV 4/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.744, test=0.736) total time=  43.2s\n",
      "[CV 2/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.742, test=0.739) total time= 1.1min\n",
      "[CV 2/5] END alpha=0.001, max_iter=1000, tol=0.0001;, score=(train=0.718, test=0.716) total time= 1.1min\n",
      "[CV 5/5] END alpha=0.001, max_iter=2000, tol=0.0001;, score=(train=0.718, test=0.713) total time=  50.1s[CV 1/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.740, test=0.739) total time=  54.4s[CV 3/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.741, test=0.740) total time= 1.2min\n",
      "\n",
      "[CV 4/5] END alpha=0.001, max_iter=2000, tol=0.0001;, score=(train=0.719, test=0.714) total time= 1.2min\n",
      "\n",
      "[CV 3/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.741, test=0.741) total time=  48.5s\n",
      "[CV 3/5] END alpha=0.01, max_iter=5000, tol=0.0001;, score=(train=0.693, test=0.693) total time= 1.2min[CV 1/5] END alpha=0.01, max_iter=10000, tol=0.001;, score=(train=0.691, test=0.692) total time=  49.8s\n",
      "\n",
      "[CV 1/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.739, test=0.739) total time= 1.2min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.743, test=0.739) total time= 1.3min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.741, test=0.740) total time= 1.4min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.744, test=0.736) total time= 1.3min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.743, test=0.739) total time= 1.3min\n",
      "[CV 3/5] END alpha=0.01, max_iter=10000, tol=0.001;, score=(train=0.693, test=0.693) total time=  31.9s\n",
      "[CV 2/5] END alpha=0.01, max_iter=5000, tol=0.001;, score=(train=0.693, test=0.688) total time=  35.6s\n",
      "[CV 4/5] END alpha=0.01, max_iter=2000, tol=0.001;, score=(train=0.694, test=0.689) total time=  38.4s[CV 1/5] END alpha=0.001, max_iter=5000, tol=0.001;, score=(train=0.716, test=0.716) total time=  39.1s\n",
      "\n",
      "[CV 1/5] END alpha=0.01, max_iter=5000, tol=0.001;, score=(train=0.691, test=0.692) total time=  45.7s\n",
      "[CV 1/5] END alpha=0.01, max_iter=2000, tol=0.001;, score=(train=0.691, test=0.692) total time=  50.8s\n",
      "[CV 4/5] END alpha=0.001, max_iter=5000, tol=0.001;, score=(train=0.719, test=0.714) total time=  47.6s\n",
      "[CV 3/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.717, test=0.718) total time=  49.6s\n",
      "[CV 5/5] END alpha=0.001, max_iter=2000, tol=0.001;, score=(train=0.718, test=0.713) total time=  45.2s\n",
      "[CV 4/5] END alpha=0.01, max_iter=10000, tol=0.001;, score=(train=0.694, test=0.689) total time=  49.5s\n",
      "[CV 3/5] END alpha=0.01, max_iter=1000, tol=0.001;, score=(train=0.693, test=0.693) total time=  42.4s\n",
      "[CV 1/5] END alpha=0.01, max_iter=1000, tol=0.001;, score=(train=0.691, test=0.692) total time=  49.6s[CV 5/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.718, test=0.713) total time=  53.9s\n",
      "\n",
      "[CV 3/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.741, test=0.740) total time=  42.4s\n",
      "[CV 2/5] END alpha=0.001, max_iter=2000, tol=0.0001;, score=(train=0.718, test=0.716) total time=  52.1s\n",
      "[CV 2/5] END alpha=0.001, max_iter=5000, tol=0.0001;, score=(train=0.718, test=0.716) total time=  45.3s\n",
      "[CV 3/5] END alpha=0.001, max_iter=2000, tol=0.001;, score=(train=0.717, test=0.718) total time=  51.1s\n",
      "[CV 2/5] END alpha=0.001, max_iter=2000, tol=0.001;, score=(train=0.718, test=0.716) total time=  51.1s[CV 2/5] END alpha=0.01, max_iter=2000, tol=0.001;, score=(train=0.693, test=0.688) total time=  47.6s\n",
      "\n",
      "[CV 1/5] END alpha=0.001, max_iter=5000, tol=0.0001;, score=(train=0.716, test=0.716) total time=  42.2s\n",
      "[CV 4/5] END alpha=0.01, max_iter=5000, tol=0.001;, score=(train=0.694, test=0.689) total time=  41.5s\n",
      "[CV 5/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.743, test=0.739) total time=  49.5s\n",
      "[CV 5/5] END alpha=0.01, max_iter=5000, tol=0.001;, score=(train=0.693, test=0.688) total time= 1.0min[CV 2/5] END alpha=0.01, max_iter=1000, tol=0.001;, score=(train=0.693, test=0.688) total time=  58.0s[CV 3/5] END alpha=0.01, max_iter=2000, tol=0.001;, score=(train=0.693, test=0.693) total time= 1.0min\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.718, test=0.716) total time= 1.0min\n",
      "[CV 5/5] END alpha=0.001, max_iter=5000, tol=0.0001;, score=(train=0.718, test=0.713) total time=  54.1s[CV 1/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.716, test=0.716) total time=  58.2s\n",
      "[CV 5/5] END alpha=0.01, max_iter=10000, tol=0.001;, score=(train=0.693, test=0.688) total time=  58.0s\n",
      "[CV 4/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.743, test=0.735) total time= 1.0min[CV 5/5] END alpha=0.01, max_iter=10000, tol=0.0001;, score=(train=0.693, test=0.688) total time=  57.1s[CV 3/5] END alpha=0.01, max_iter=5000, tol=0.001;, score=(train=0.693, test=0.693) total time= 1.0min[CV 2/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.742, test=0.739) total time=  57.1s\n",
      "[CV 4/5] END alpha=0.001, max_iter=10000, tol=0.0001;, score=(train=0.719, test=0.714) total time=  59.6s\n",
      "[CV 4/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.719, test=0.714) total time=  49.4s\n",
      "\n",
      "\n",
      "[CV 5/5] END alpha=0.001, max_iter=5000, tol=0.001;, score=(train=0.718, test=0.713) total time= 1.0min\n",
      "[CV 3/5] END alpha=0.001, max_iter=10000, tol=0.0001;, score=(train=0.717, test=0.718) total time=  42.2s\n",
      "\n",
      "\n",
      "[CV 1/5] END alpha=0.001, max_iter=10000, tol=0.0001;, score=(train=0.716, test=0.716) total time= 1.0min\n",
      "[CV 5/5] END alpha=0.001, max_iter=10000, tol=0.0001;, score=(train=0.718, test=0.713) total time=  59.5s\n",
      "[CV 1/5] END alpha=0.001, max_iter=2000, tol=0.0001;, score=(train=0.716, test=0.716) total time= 1.1min[CV 3/5] END alpha=0.001, max_iter=5000, tol=0.001;, score=(train=0.717, test=0.718) total time= 1.1min[CV 5/5] END alpha=0.01, max_iter=2000, tol=0.001;, score=(train=0.693, test=0.688) total time= 1.1min[CV 3/5] END alpha=0.001, max_iter=5000, tol=0.0001;, score=(train=0.717, test=0.718) total time= 1.2min\n",
      "\n",
      "\n",
      "\n",
      "[CV 4/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.743, test=0.735) total time=  59.4s\n",
      "[CV 4/5] END alpha=0.01, max_iter=1000, tol=0.001;, score=(train=0.694, test=0.689) total time=  58.1s\n",
      "[CV 1/5] END alpha=0.001, max_iter=2000, tol=0.001;, score=(train=0.716, test=0.716) total time= 1.1min\n",
      "[CV 2/5] END alpha=0.01, max_iter=10000, tol=0.0001;, score=(train=0.693, test=0.688) total time= 1.2min\n",
      "[CV 3/5] END alpha=0.01, max_iter=1000, tol=0.0001;, score=(train=0.693, test=0.693) total time= 1.2min\n",
      "[CV 4/5] END alpha=0.001, max_iter=5000, tol=0.0001;, score=(train=0.719, test=0.714) total time= 1.1min[CV 4/5] END alpha=0.001, max_iter=2000, tol=0.001;, score=(train=0.719, test=0.714) total time= 1.1min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.740, test=0.740) total time= 1.1min\n",
      "\n",
      "[CV 3/5] END alpha=0.01, max_iter=2000, tol=0.0001;, score=(train=0.693, test=0.693) total time= 1.1min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.743, test=0.739) total time= 1.1min\n",
      "[CV 1/5] END alpha=0.01, max_iter=1000, tol=0.0001;, score=(train=0.691, test=0.692) total time= 1.2min[CV 5/5] END alpha=0.01, max_iter=1000, tol=0.001;, score=(train=0.693, test=0.688) total time= 1.1min[CV 3/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.741, test=0.740) total time= 1.1min\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=0.001, max_iter=5000, tol=0.001;, score=(train=0.718, test=0.716) total time= 1.1min\n",
      "[CV 5/5] END alpha=0.01, max_iter=5000, tol=0.0001;, score=(train=0.693, test=0.688) total time= 1.2min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.743, test=0.739) total time= 1.2min\n",
      "[CV 2/5] END alpha=0.01, max_iter=5000, tol=0.0001;, score=(train=0.693, test=0.688) total time= 1.2min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.741, test=0.740) total time=  57.1s\n",
      "[CV 4/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.744, test=0.736) total time= 1.2min\n",
      "[CV 3/5] END alpha=0.01, max_iter=10000, tol=0.0001;, score=(train=0.693, test=0.693) total time= 1.2min[CV 4/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.743, test=0.735) total time= 1.2min[CV 4/5] END alpha=0.01, max_iter=5000, tol=0.0001;, score=(train=0.694, test=0.689) total time= 1.2min[CV 1/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.740, test=0.740) total time= 1.2min\n",
      "\n",
      "\n",
      "\n",
      "[CV 5/5] END alpha=0.01, max_iter=2000, tol=0.0001;, score=(train=0.693, test=0.688) total time= 1.2min\n",
      "[CV 1/5] END alpha=0.01, max_iter=5000, tol=0.0001;, score=(train=0.691, test=0.692) total time= 1.2min\n",
      "[CV 4/5] END alpha=0.01, max_iter=1000, tol=0.0001;, score=(train=0.694, test=0.689) total time= 1.2min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.741, test=0.740) total time= 1.2min\n",
      "[CV 4/5] END alpha=0.01, max_iter=10000, tol=0.0001;, score=(train=0.694, test=0.689) total time= 1.2min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.743, test=0.739) total time= 1.2min\n",
      "[CV 4/5] END alpha=0.01, max_iter=2000, tol=0.0001;, score=(train=0.694, test=0.689) total time= 1.2min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.742, test=0.739) total time= 1.2min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.742, test=0.739) total time= 1.2min\n",
      "[CV 5/5] END alpha=0.01, max_iter=1000, tol=0.0001;, score=(train=0.693, test=0.688) total time= 1.3min\n",
      "[CV 1/5] END alpha=0.01, max_iter=10000, tol=0.0001;, score=(train=0.691, test=0.692) total time= 1.3min\n",
      "[CV 2/5] END alpha=0.01, max_iter=2000, tol=0.0001;, score=(train=0.693, test=0.688) total time= 1.3min\n",
      "[CV 1/5] END alpha=0.01, max_iter=2000, tol=0.0001;, score=(train=0.691, test=0.692) total time= 1.3min\n",
      "[CV 2/5] END alpha=0.01, max_iter=1000, tol=0.0001;, score=(train=0.693, test=0.688) total time= 1.3min\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 12\n",
      "n_resources: 470056\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 3/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.739, test=0.740) total time= 1.3min\n",
      "[CV 2/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.717, test=0.718) total time= 1.3min\n",
      "[CV 1/5] END alpha=0.001, max_iter=5000, tol=0.0001;, score=(train=0.718, test=0.717) total time= 1.5min[CV 1/5] END alpha=0.001, max_iter=5000, tol=0.001;, score=(train=0.718, test=0.717) total time= 1.5min\n",
      "\n",
      "[CV 3/5] END alpha=0.001, max_iter=5000, tol=0.001;, score=(train=0.718, test=0.719) total time= 1.5min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.741, test=0.738) total time= 1.4min\n",
      "[CV 1/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.718, test=0.717) total time= 1.5min\n",
      "[CV 1/5] END alpha=0.001, max_iter=10000, tol=0.0001;, score=(train=0.718, test=0.717) total time= 1.5min\n",
      "[CV 4/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.717, test=0.717) total time= 1.5min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.739, test=0.739) total time= 1.5min\n",
      "[CV 5/5] END alpha=0.001, max_iter=5000, tol=0.0001;, score=(train=0.718, test=0.716) total time= 1.6min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.741, test=0.738) total time= 1.7min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.739, test=0.739) total time= 1.7min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.741, test=0.739) total time= 1.7min\n",
      "[CV 5/5] END alpha=0.001, max_iter=5000, tol=0.001;, score=(train=0.718, test=0.716) total time= 1.7min\n",
      "[CV 4/5] END alpha=0.001, max_iter=5000, tol=0.0001;, score=(train=0.717, test=0.717) total time= 1.7min[CV 5/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.718, test=0.716) total time= 1.7min\n",
      "\n",
      "[CV 4/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.741, test=0.739) total time= 1.7min\n",
      "[CV 2/5] END alpha=0.001, max_iter=5000, tol=0.001;, score=(train=0.717, test=0.718) total time= 1.7min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.741, test=0.738) total time= 1.7min\n",
      "[CV 4/5] END alpha=0.001, max_iter=5000, tol=0.001;, score=(train=0.717, test=0.717) total time= 1.8min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.739, test=0.740) total time= 1.8min\n",
      "[CV 4/5] END alpha=0.001, max_iter=10000, tol=0.0001;, score=(train=0.717, test=0.717) total time= 1.7min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.739, test=0.740) total time= 1.7min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.741, test=0.738) total time= 1.8min\n",
      "[CV 5/5] END alpha=0.001, max_iter=10000, tol=0.0001;, score=(train=0.718, test=0.716) total time= 1.8min\n",
      "[CV 3/5] END alpha=0.001, max_iter=5000, tol=0.0001;, score=(train=0.718, test=0.719) total time= 1.8min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.739, test=0.739) total time= 1.8min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.740, test=0.739) total time= 1.8min\n",
      "[CV 2/5] END alpha=0.001, max_iter=5000, tol=0.0001;, score=(train=0.717, test=0.718) total time= 1.8min\n",
      "[CV 3/5] END alpha=0.001, max_iter=10000, tol=0.001;, score=(train=0.718, test=0.719) total time= 1.8min[CV 1/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.739, test=0.739) total time= 1.8min[CV 4/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.741, test=0.739) total time= 1.8min\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.739, test=0.739) total time= 1.9min\n",
      "[CV 3/5] END alpha=0.001, max_iter=10000, tol=0.0001;, score=(train=0.718, test=0.719) total time= 1.9min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.739, test=0.738) total time= 1.8min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.739, test=0.739) total time= 2.0min\n",
      "[CV 2/5] END alpha=0.001, max_iter=10000, tol=0.0001;, score=(train=0.717, test=0.718) total time= 2.0min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.739, test=0.738) total time= 2.0min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.739, test=0.740) total time= 1.9min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.740, test=0.740) total time= 1.9min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.741, test=0.739) total time= 2.0min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.739, test=0.738) total time= 2.0min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.739, test=0.739) total time= 2.0min[CV 3/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.739, test=0.740) total time= 2.0min\n",
      "\n",
      "[CV 1/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.739, test=0.738) total time= 2.0min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.741, test=0.739) total time= 2.0min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.739, test=0.740) total time= 2.0min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.739, test=0.739) total time= 2.0min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.739, test=0.739) total time= 2.1min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.739, test=0.739) total time= 2.1min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.739, test=0.738) total time= 2.1min[CV 5/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.741, test=0.738) total time= 2.1min\n",
      "\n",
      "[CV 5/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.741, test=0.738) total time= 2.1min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.741, test=0.738) total time= 2.1min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=2000, tol=0.0001;, score=(train=0.740, test=0.738) total time= 2.1min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.739, test=0.740) total time= 2.1min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.741, test=0.739) total time= 2.1min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.741, test=0.739) total time= 2.1min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=1000, tol=0.0001;, score=(train=0.739, test=0.739) total time= 2.1min\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 6\n",
      "n_resources: 940112\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.739, test=0.741) total time=  10.3s\n",
      "[CV 2/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.739, test=0.739) total time= 1.0min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.739, test=0.739) total time= 1.1min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.738, test=0.738) total time= 1.1min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.739, test=0.739) total time= 1.0min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.739, test=0.739) total time= 1.2min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.738, test=0.737) total time= 1.2min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.739, test=0.739) total time= 1.3min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.739, test=0.741) total time= 1.3min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.740, test=0.739) total time= 1.3min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.738, test=0.738) total time= 1.2min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.739, test=0.739) total time= 1.2min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.739, test=0.741) total time= 1.3min[CV 1/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.739, test=0.741) total time= 1.3min[CV 1/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.739, test=0.741) total time= 1.3min\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.739, test=0.739) total time= 1.3min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.740, test=0.739) total time= 1.3min\n",
      "[CV 1/5] END alpha=0.0001, max_iter=5000, tol=0.001;, score=(train=0.739, test=0.741) total time= 1.3min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.740, test=0.739) total time= 1.3min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.740, test=0.739) total time= 1.4min[CV 4/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.739, test=0.739) total time= 1.4min\n",
      "\n",
      "[CV 3/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.738, test=0.737) total time= 1.4min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.739, test=0.739) total time= 1.4min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.738, test=0.739) total time= 1.4min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.739, test=0.739) total time= 1.4min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.740, test=0.739) total time= 1.5min[CV 3/5] END alpha=0.0001, max_iter=10000, tol=0.0001;, score=(train=0.738, test=0.737) total time= 1.4min\n",
      "\n",
      "[CV 3/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.738, test=0.737) total time= 1.5min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.740, test=0.739) total time= 1.5min[CV 4/5] END alpha=0.0001, max_iter=5000, tol=0.0001;, score=(train=0.739, test=0.739) total time= 1.4min\n",
      "\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 1880224\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.738, test=0.738) total time= 1.3min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.738, test=0.738) total time= 1.4min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.739, test=0.740) total time= 1.4min[CV 5/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.738, test=0.737) total time= 1.4min[CV 4/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.740, test=0.738) total time= 1.4min\n",
      "\n",
      "\n",
      "[CV 2/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.739, test=0.740) total time= 1.4min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.738, test=0.737) total time= 1.4min[CV 1/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.738, test=0.738) total time= 1.5min[CV 1/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.738, test=0.738) total time= 1.4min[CV 4/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.740, test=0.738) total time= 1.4min\n",
      "\n",
      "\n",
      "\n",
      "[CV 5/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.738, test=0.737) total time= 1.5min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.740, test=0.738) total time= 1.4min\n",
      "[CV 3/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.738, test=0.738) total time= 1.5min[CV 2/5] END alpha=0.0001, max_iter=2000, tol=0.001;, score=(train=0.739, test=0.740) total time= 1.5min\n",
      "\n",
      "[CV 3/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.738, test=0.738) total time= 1.5min\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 2\n",
      "n_resources: 3760448\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.738, test=0.738) total time= 1.8min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.738, test=0.738) total time= 1.9min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.739, test=0.739) total time= 1.9min\n",
      "[CV 4/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.739, test=0.738) total time= 1.9min[CV 1/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.738, test=0.738) total time= 1.9min\n",
      "\n",
      "[CV 4/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.738, test=0.738) total time= 1.9min[CV 3/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.739, test=0.739) total time= 2.0min\n",
      "\n",
      "[CV 3/5] END alpha=0.0001, max_iter=10000, tol=0.001;, score=(train=0.739, test=0.739) total time= 2.0min\n",
      "[CV 5/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.738, test=0.738) total time= 2.0min\n",
      "[CV 2/5] END alpha=0.0001, max_iter=1000, tol=0.001;, score=(train=0.739, test=0.739) total time= 1.9min\n",
      "Best Parameters: {'alpha': 0.0001, 'max_iter': 1000, 'tol': 0.001}\n",
      "Best Validation F1-score: 0.7382585661865185\n",
      "Best model f1 score: 0.7368977088535842\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "grid_search = HalvingGridSearchCV(\n",
    "    estimator=SGDClassifier(loss=\"hinge\"),\n",
    "    param_grid=param_grid,\n",
    "    factor=2,  \n",
    "    cv=5,\n",
    "    scoring=\"f1_weighted\",\n",
    "    n_jobs=-1,\n",
    "    verbose=3\n",
    ")\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Validation F1-score:\", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_tfidf = best_model.predict(X_test_tfidf)\n",
    "f1_tfidf = f1_score(y_test, y_pred_tfidf, average='weighted')\n",
    "print(\"Best model f1 score:\", f1_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7754243372871134\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_tfidf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
